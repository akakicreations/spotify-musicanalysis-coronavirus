{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top200 SpotifyCharts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso:\n",
    " - Sacar top200 de 2017, 2018, 2019 y 2010\n",
    " - De canciones duplicadas sumar los Streams y unir, quitar duplicados\n",
    " - Juntar Dataframes de años y añadir una nueva columna con el mismo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Días totales seleccionados 2020: 60 days, 0:00:00\n",
      "Días totales seleccionados 2019: 60 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "# Help: https://github.com/kelvingakuo/fycharts#in\n",
    "#! pip install fycharts\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "\n",
    "#Fechas 2020\n",
    "fecha_fin_2020 = '2020-05-13' # Empieza a levantarse restricciones de salida\n",
    "fecha_inicial_2020 = '2020-03-14' #14 Marzo se decreta el estado de alarma, con 5753 casos y 136 fallecidos\n",
    "fecha_fin2_2020 = datetime.strptime(fecha_fin_2020, '%Y-%m-%d')\n",
    "fecha_inicial2_2020 = datetime.strptime(fecha_inicial_2020, '%Y-%m-%d')\n",
    "\n",
    "#Fechas 2019\n",
    "fecha_fin_2019 = '2019-05-13'\n",
    "fecha_inicial_2019 = '2019-03-14'\n",
    "fecha_fin2_2019 = datetime.strptime(fecha_fin_2019, '%Y-%m-%d')\n",
    "fecha_inicial2_2019 = datetime.strptime(fecha_inicial_2019, '%Y-%m-%d')\n",
    "\n",
    "print('Días totales seleccionados 2020:', fecha_fin2_2020 - fecha_inicial2_2020)\n",
    "print('Días totales seleccionados 2019:', fecha_fin2_2019 - fecha_inicial2_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 12/07/2020 05:09:08 PM : Extracting top 200 daily for 2020-03-14 - es\n",
      "INFO : 12/07/2020 05:09:09 PM : Extracting top 200 daily for 2020-03-15 - es\n",
      "INFO : 12/07/2020 05:09:09 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:09 PM : POSTing data to the endpoint h\n",
      "INFO : 12/07/2020 05:09:09 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "Exception in thread Thread-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/SpotifyCharts.py\", line 87, in __post_to_endpoint_from_queue\n",
      "    postToRestEndpoint(df, url, what_data)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/write_to_outputs.py\", line 54, in postToRestEndpoint\n",
      "    raise(e)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/write_to_outputs.py\", line 51, in postToRestEndpoint\n",
      "    requests.post(url, json = dump)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 516, in request\n",
      "    prep = self.prepare_request(req)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 459, in prepare_request\n",
      "    hooks=merge_hooks(request.hooks, self.hooks),\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/models.py\", line 314, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/models.py\", line 388, in prepare_url\n",
      "    raise MissingSchema(error)\n",
      "requests.exceptions.MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/SpotifyCharts.py\", line 89, in __post_to_endpoint_from_queue\n",
      "    raise RuntimeError(e)\n",
      "RuntimeError: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?\n",
      "\n",
      "INFO : 12/07/2020 05:09:09 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:09 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:10 PM : Extracting top 200 daily for 2020-03-16 - es\n",
      "INFO : 12/07/2020 05:09:10 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:10 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:10 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:10 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:11 PM : Extracting top 200 daily for 2020-03-17 - es\n",
      "INFO : 12/07/2020 05:09:11 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:11 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:11 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:11 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:12 PM : Extracting top 200 daily for 2020-03-18 - es\n",
      "INFO : 12/07/2020 05:09:12 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:12 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:12 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:12 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:13 PM : Extracting top 200 daily for 2020-03-19 - es\n",
      "INFO : 12/07/2020 05:09:13 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:13 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:13 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:13 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:13 PM : Extracting top 200 daily for 2020-03-20 - es\n",
      "INFO : 12/07/2020 05:09:13 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:13 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:14 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:14 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:14 PM : Extracting top 200 daily for 2020-03-21 - es\n",
      "INFO : 12/07/2020 05:09:14 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:14 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:14 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:14 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:15 PM : Extracting top 200 daily for 2020-03-22 - es\n",
      "INFO : 12/07/2020 05:09:15 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:15 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:15 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:15 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:16 PM : Extracting top 200 daily for 2020-03-23 - es\n",
      "INFO : 12/07/2020 05:09:16 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:16 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:16 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:16 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:17 PM : Extracting top 200 daily for 2020-03-24 - es\n",
      "INFO : 12/07/2020 05:09:17 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:17 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:17 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:17 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:18 PM : Extracting top 200 daily for 2020-03-25 - es\n",
      "INFO : 12/07/2020 05:09:18 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:18 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:18 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:18 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:19 PM : Extracting top 200 daily for 2020-03-26 - es\n",
      "INFO : 12/07/2020 05:09:19 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:19 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:19 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:19 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:20 PM : Extracting top 200 daily for 2020-03-27 - es\n",
      "INFO : 12/07/2020 05:09:20 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:20 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:20 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:20 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:21 PM : Extracting top 200 daily for 2020-03-28 - es\n",
      "INFO : 12/07/2020 05:09:21 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:21 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:21 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:21 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:23 PM : Extracting top 200 daily for 2020-03-29 - es\n",
      "INFO : 12/07/2020 05:09:23 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:23 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:23 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:23 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:23 PM : Extracting top 200 daily for 2020-03-30 - es\n",
      "INFO : 12/07/2020 05:09:23 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:23 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:24 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:24 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:24 PM : Extracting top 200 daily for 2020-03-31 - es\n",
      "INFO : 12/07/2020 05:09:24 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:24 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:24 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:24 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:25 PM : Extracting top 200 daily for 2020-04-01 - es\n",
      "INFO : 12/07/2020 05:09:25 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:25 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:25 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:25 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:26 PM : Extracting top 200 daily for 2020-04-02 - es\n",
      "INFO : 12/07/2020 05:09:26 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:26 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:26 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:26 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:27 PM : Extracting top 200 daily for 2020-04-03 - es\n",
      "INFO : 12/07/2020 05:09:27 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:27 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:27 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:27 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:28 PM : Extracting top 200 daily for 2020-04-04 - es\n",
      "INFO : 12/07/2020 05:09:28 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:28 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:28 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:28 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:29 PM : Extracting top 200 daily for 2020-04-05 - es\n",
      "INFO : 12/07/2020 05:09:29 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:29 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:29 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:29 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:30 PM : Extracting top 200 daily for 2020-04-06 - es\n",
      "INFO : 12/07/2020 05:09:30 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:30 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:30 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:30 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:31 PM : Extracting top 200 daily for 2020-04-07 - es\n",
      "INFO : 12/07/2020 05:09:31 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:31 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:31 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:31 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:31 PM : Extracting top 200 daily for 2020-04-08 - es\n",
      "INFO : 12/07/2020 05:09:31 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:31 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:31 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:31 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:32 PM : Extracting top 200 daily for 2020-04-09 - es\n",
      "INFO : 12/07/2020 05:09:32 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:32 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:32 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:32 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:33 PM : Extracting top 200 daily for 2020-04-10 - es\n",
      "INFO : 12/07/2020 05:09:33 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:33 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:33 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:33 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:34 PM : Extracting top 200 daily for 2020-04-11 - es\n",
      "INFO : 12/07/2020 05:09:34 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:34 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:34 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:34 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:34 PM : Extracting top 200 daily for 2020-04-12 - es\n",
      "INFO : 12/07/2020 05:09:34 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:34 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:34 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:34 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:35 PM : Extracting top 200 daily for 2020-04-13 - es\n",
      "INFO : 12/07/2020 05:09:35 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:35 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:35 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:35 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:36 PM : Extracting top 200 daily for 2020-04-14 - es\n",
      "INFO : 12/07/2020 05:09:36 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:36 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:36 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:36 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:37 PM : Extracting top 200 daily for 2020-04-15 - es\n",
      "INFO : 12/07/2020 05:09:37 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:37 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:37 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:37 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:37 PM : Extracting top 200 daily for 2020-04-16 - es\n",
      "INFO : 12/07/2020 05:09:37 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:37 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:37 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:37 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:38 PM : Extracting top 200 daily for 2020-04-17 - es\n",
      "INFO : 12/07/2020 05:09:38 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:38 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:38 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:38 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:39 PM : Extracting top 200 daily for 2020-04-18 - es\n",
      "INFO : 12/07/2020 05:09:39 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:39 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:39 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:39 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:40 PM : Extracting top 200 daily for 2020-04-19 - es\n",
      "INFO : 12/07/2020 05:09:40 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:40 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:40 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:40 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:41 PM : Extracting top 200 daily for 2020-04-20 - es\n",
      "INFO : 12/07/2020 05:09:41 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:41 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:41 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:41 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:42 PM : Extracting top 200 daily for 2020-04-21 - es\n",
      "INFO : 12/07/2020 05:09:42 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:42 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:42 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:42 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:43 PM : Extracting top 200 daily for 2020-04-22 - es\n",
      "INFO : 12/07/2020 05:09:43 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:43 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:43 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:43 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:43 PM : Extracting top 200 daily for 2020-04-23 - es\n",
      "INFO : 12/07/2020 05:09:43 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:43 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:43 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:43 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:44 PM : Extracting top 200 daily for 2020-04-24 - es\n",
      "INFO : 12/07/2020 05:09:44 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:44 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:44 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:44 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:45 PM : Extracting top 200 daily for 2020-04-25 - es\n",
      "INFO : 12/07/2020 05:09:45 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:45 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:45 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:45 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:45 PM : Extracting top 200 daily for 2020-04-26 - es\n",
      "INFO : 12/07/2020 05:09:45 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:45 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:45 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:45 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:46 PM : Extracting top 200 daily for 2020-04-27 - es\n",
      "INFO : 12/07/2020 05:09:46 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:46 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:46 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:47 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:47 PM : Extracting top 200 daily for 2020-04-28 - es\n",
      "INFO : 12/07/2020 05:09:47 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:47 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:47 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:47 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:48 PM : Extracting top 200 daily for 2020-04-29 - es\n",
      "INFO : 12/07/2020 05:09:48 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:48 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:48 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:48 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:48 PM : Extracting top 200 daily for 2020-04-30 - es\n",
      "INFO : 12/07/2020 05:09:48 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:48 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:48 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:48 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:49 PM : Extracting top 200 daily for 2020-05-01 - es\n",
      "INFO : 12/07/2020 05:09:49 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:49 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:49 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:49 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:50 PM : Extracting top 200 daily for 2020-05-02 - es\n",
      "INFO : 12/07/2020 05:09:50 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:50 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:50 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:50 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:51 PM : Extracting top 200 daily for 2020-05-03 - es\n",
      "INFO : 12/07/2020 05:09:51 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:51 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:51 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:51 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:51 PM : Extracting top 200 daily for 2020-05-04 - es\n",
      "INFO : 12/07/2020 05:09:51 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:51 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:51 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:51 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:52 PM : Extracting top 200 daily for 2020-05-05 - es\n",
      "INFO : 12/07/2020 05:09:52 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:52 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:52 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:52 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:53 PM : Extracting top 200 daily for 2020-05-06 - es\n",
      "INFO : 12/07/2020 05:09:53 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:53 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:53 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:53 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:53 PM : Extracting top 200 daily for 2020-05-07 - es\n",
      "INFO : 12/07/2020 05:09:53 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:53 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:53 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:53 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:54 PM : Extracting top 200 daily for 2020-05-08 - es\n",
      "INFO : 12/07/2020 05:09:54 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:54 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:54 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:54 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:55 PM : Extracting top 200 daily for 2020-05-09 - es\n",
      "INFO : 12/07/2020 05:09:55 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:55 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:55 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:55 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:56 PM : Extracting top 200 daily for 2020-05-10 - es\n",
      "INFO : 12/07/2020 05:09:56 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:56 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:56 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:56 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:57 PM : Extracting top 200 daily for 2020-05-11 - es\n",
      "INFO : 12/07/2020 05:09:57 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:57 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:57 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:57 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:57 PM : Extracting top 200 daily for 2020-05-12 - es\n",
      "INFO : 12/07/2020 05:09:57 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:57 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:57 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:57 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:58 PM : Extracting top 200 daily for 2020-05-13 - es\n",
      "INFO : 12/07/2020 05:09:58 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:58 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:58 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:58 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:09:59 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:09:59 PM : Appending data to the file top_200_daily_2020.csv...\n",
      "INFO : 12/07/2020 05:09:59 PM : Extracting top 200 daily for 2019-03-14 - es\n",
      "INFO : 12/07/2020 05:09:59 PM : Done appending to the file top_200_daily_2020.csv!!!\n",
      "INFO : 12/07/2020 05:09:59 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:01 PM : Extracting top 200 daily for 2019-03-15 - es\n",
      "INFO : 12/07/2020 05:10:01 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:01 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:01 PM : POSTing data to the endpoint h\n",
      "INFO : 12/07/2020 05:10:01 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/SpotifyCharts.py\", line 87, in __post_to_endpoint_from_queue\n",
      "    postToRestEndpoint(df, url, what_data)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/write_to_outputs.py\", line 54, in postToRestEndpoint\n",
      "    raise(e)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/write_to_outputs.py\", line 51, in postToRestEndpoint\n",
      "    requests.post(url, json = dump)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 516, in request\n",
      "    prep = self.prepare_request(req)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/sessions.py\", line 459, in prepare_request\n",
      "    hooks=merge_hooks(request.hooks, self.hooks),\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/models.py\", line 314, in prepare\n",
      "    self.prepare_url(url, params)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/requests/models.py\", line 388, in prepare_url\n",
      "    raise MissingSchema(error)\n",
      "requests.exceptions.MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/victormac/anaconda3/lib/python3.7/site-packages/fycharts/SpotifyCharts.py\", line 89, in __post_to_endpoint_from_queue\n",
      "    raise RuntimeError(e)\n",
      "RuntimeError: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?\n",
      "\n",
      "INFO : 12/07/2020 05:10:01 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:02 PM : Extracting top 200 daily for 2019-03-16 - es\n",
      "INFO : 12/07/2020 05:10:02 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:02 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:02 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:02 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:03 PM : Extracting top 200 daily for 2019-03-17 - es\n",
      "INFO : 12/07/2020 05:10:03 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:03 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:03 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:03 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:05 PM : Extracting top 200 daily for 2019-03-18 - es\n",
      "INFO : 12/07/2020 05:10:05 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:05 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:05 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:05 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:06 PM : Extracting top 200 daily for 2019-03-19 - es\n",
      "INFO : 12/07/2020 05:10:06 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:06 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:06 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:06 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:07 PM : Extracting top 200 daily for 2019-03-20 - es\n",
      "INFO : 12/07/2020 05:10:07 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:07 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:07 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:07 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:08 PM : Extracting top 200 daily for 2019-03-21 - es\n",
      "INFO : 12/07/2020 05:10:08 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:08 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:08 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:08 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:09 PM : Extracting top 200 daily for 2019-03-22 - es\n",
      "INFO : 12/07/2020 05:10:09 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:09 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:09 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:09 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:11 PM : Extracting top 200 daily for 2019-03-23 - es\n",
      "INFO : 12/07/2020 05:10:11 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:11 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:11 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:11 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:12 PM : Extracting top 200 daily for 2019-03-24 - es\n",
      "INFO : 12/07/2020 05:10:12 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:12 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:12 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:12 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:13 PM : Extracting top 200 daily for 2019-03-25 - es\n",
      "INFO : 12/07/2020 05:10:13 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:13 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:13 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:13 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:14 PM : Extracting top 200 daily for 2019-03-26 - es\n",
      "INFO : 12/07/2020 05:10:14 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:14 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:14 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:14 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:15 PM : Extracting top 200 daily for 2019-03-27 - es\n",
      "INFO : 12/07/2020 05:10:15 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:15 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:15 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:15 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:16 PM : Extracting top 200 daily for 2019-03-28 - es\n",
      "INFO : 12/07/2020 05:10:16 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:16 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:16 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:16 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:17 PM : Extracting top 200 daily for 2019-03-29 - es\n",
      "INFO : 12/07/2020 05:10:17 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:17 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:17 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:17 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:19 PM : Extracting top 200 daily for 2019-03-30 - es\n",
      "INFO : 12/07/2020 05:10:19 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:19 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:19 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:19 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:20 PM : Extracting top 200 daily for 2019-03-31 - es\n",
      "INFO : 12/07/2020 05:10:20 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:20 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:20 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:20 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:21 PM : Extracting top 200 daily for 2019-04-01 - es\n",
      "INFO : 12/07/2020 05:10:21 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:21 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:21 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:21 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:23 PM : Extracting top 200 daily for 2019-04-02 - es\n",
      "INFO : 12/07/2020 05:10:23 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:23 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:23 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:23 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:23 PM : Extracting top 200 daily for 2019-04-03 - es\n",
      "INFO : 12/07/2020 05:10:23 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:23 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:23 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:23 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:24 PM : Extracting top 200 daily for 2019-04-04 - es\n",
      "INFO : 12/07/2020 05:10:24 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:24 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:24 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:24 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:25 PM : Extracting top 200 daily for 2019-04-05 - es\n",
      "INFO : 12/07/2020 05:10:25 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:25 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:25 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:25 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:27 PM : Extracting top 200 daily for 2019-04-06 - es\n",
      "INFO : 12/07/2020 05:10:27 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:27 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:27 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:27 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:28 PM : Extracting top 200 daily for 2019-04-07 - es\n",
      "INFO : 12/07/2020 05:10:28 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:28 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:28 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:28 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:29 PM : Extracting top 200 daily for 2019-04-08 - es\n",
      "INFO : 12/07/2020 05:10:29 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:29 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:29 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:29 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:30 PM : Extracting top 200 daily for 2019-04-09 - es\n",
      "INFO : 12/07/2020 05:10:30 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:30 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:30 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:30 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:32 PM : Extracting top 200 daily for 2019-04-10 - es\n",
      "INFO : 12/07/2020 05:10:32 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:32 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:32 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:32 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:33 PM : Extracting top 200 daily for 2019-04-11 - es\n",
      "INFO : 12/07/2020 05:10:33 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:33 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:33 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:33 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:34 PM : Extracting top 200 daily for 2019-04-12 - es\n",
      "INFO : 12/07/2020 05:10:34 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:34 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:34 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:34 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:36 PM : Extracting top 200 daily for 2019-04-13 - es\n",
      "INFO : 12/07/2020 05:10:36 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:36 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:36 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:36 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:37 PM : Extracting top 200 daily for 2019-04-14 - es\n",
      "INFO : 12/07/2020 05:10:37 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:37 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:37 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:37 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:38 PM : Extracting top 200 daily for 2019-04-15 - es\n",
      "INFO : 12/07/2020 05:10:38 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:38 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:38 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:38 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:40 PM : Extracting top 200 daily for 2019-04-16 - es\n",
      "INFO : 12/07/2020 05:10:40 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:40 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:40 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:40 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:40 PM : Extracting top 200 daily for 2019-04-17 - es\n",
      "INFO : 12/07/2020 05:10:40 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:40 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:40 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:40 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:42 PM : Extracting top 200 daily for 2019-04-18 - es\n",
      "INFO : 12/07/2020 05:10:42 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:42 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:42 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:42 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:43 PM : Extracting top 200 daily for 2019-04-19 - es\n",
      "INFO : 12/07/2020 05:10:43 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:43 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:43 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:43 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:44 PM : Extracting top 200 daily for 2019-04-20 - es\n",
      "INFO : 12/07/2020 05:10:44 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:44 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:44 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:44 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:46 PM : Extracting top 200 daily for 2019-04-21 - es\n",
      "INFO : 12/07/2020 05:10:46 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:46 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:46 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:46 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:46 PM : Extracting top 200 daily for 2019-04-22 - es\n",
      "INFO : 12/07/2020 05:10:46 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:46 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:46 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:46 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:47 PM : Extracting top 200 daily for 2019-04-23 - es\n",
      "INFO : 12/07/2020 05:10:47 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:47 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:47 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:47 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:49 PM : Extracting top 200 daily for 2019-04-24 - es\n",
      "INFO : 12/07/2020 05:10:49 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:49 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:49 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:49 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:50 PM : Extracting top 200 daily for 2019-04-25 - es\n",
      "INFO : 12/07/2020 05:10:50 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:50 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:50 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:50 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:51 PM : Extracting top 200 daily for 2019-04-26 - es\n",
      "INFO : 12/07/2020 05:10:51 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:51 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:51 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:51 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:52 PM : Extracting top 200 daily for 2019-04-27 - es\n",
      "INFO : 12/07/2020 05:10:52 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:52 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:52 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:52 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:54 PM : Extracting top 200 daily for 2019-04-28 - es\n",
      "INFO : 12/07/2020 05:10:54 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:54 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:54 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:54 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:55 PM : Extracting top 200 daily for 2019-04-29 - es\n",
      "INFO : 12/07/2020 05:10:55 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:55 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:55 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:55 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:56 PM : Extracting top 200 daily for 2019-04-30 - es\n",
      "INFO : 12/07/2020 05:10:56 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:56 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:56 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:56 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:57 PM : Extracting top 200 daily for 2019-05-01 - es\n",
      "INFO : 12/07/2020 05:10:57 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:57 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:57 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:57 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:10:58 PM : Extracting top 200 daily for 2019-05-02 - es\n",
      "INFO : 12/07/2020 05:10:58 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:10:58 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:10:58 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:10:58 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:00 PM : Extracting top 200 daily for 2019-05-03 - es\n",
      "INFO : 12/07/2020 05:11:00 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:00 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:00 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:00 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:01 PM : Extracting top 200 daily for 2019-05-04 - es\n",
      "INFO : 12/07/2020 05:11:01 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:01 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:01 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:01 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:02 PM : Extracting top 200 daily for 2019-05-05 - es\n",
      "INFO : 12/07/2020 05:11:02 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:02 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:02 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:02 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:03 PM : Extracting top 200 daily for 2019-05-06 - es\n",
      "INFO : 12/07/2020 05:11:03 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:03 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:03 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:03 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:05 PM : Extracting top 200 daily for 2019-05-07 - es\n",
      "INFO : 12/07/2020 05:11:05 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:05 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:05 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:05 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:06 PM : Extracting top 200 daily for 2019-05-08 - es\n",
      "INFO : 12/07/2020 05:11:06 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:06 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:06 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:06 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:07 PM : Extracting top 200 daily for 2019-05-09 - es\n",
      "INFO : 12/07/2020 05:11:07 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:07 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:07 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:07 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:08 PM : Extracting top 200 daily for 2019-05-10 - es\n",
      "INFO : 12/07/2020 05:11:08 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:08 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:08 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:08 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:10 PM : Extracting top 200 daily for 2019-05-11 - es\n",
      "INFO : 12/07/2020 05:11:10 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:10 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:10 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:10 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:11 PM : Extracting top 200 daily for 2019-05-12 - es\n",
      "INFO : 12/07/2020 05:11:11 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:11 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:11 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:11 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:12 PM : Extracting top 200 daily for 2019-05-13 - es\n",
      "INFO : 12/07/2020 05:11:12 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:12 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:12 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:12 PM : Done appending to the table top_200_daily!!!\n",
      "INFO : 12/07/2020 05:11:13 PM : Appending data to the table top_200_daily\n",
      "INFO : 12/07/2020 05:11:13 PM : Appending data to the file top_200_daily_2019.csv...\n",
      "INFO : 12/07/2020 05:11:13 PM : Done appending to the file top_200_daily_2019.csv!!!\n",
      "INFO : 12/07/2020 05:11:13 PM : Done appending to the table top_200_daily!!!\n"
     ]
    }
   ],
   "source": [
    "# ¡IMPORTANTE! Ejecutar una única vez para descargar los datos, configurado para España\n",
    "'''\n",
    "# Descarga año 2020\n",
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "import sqlalchemy\n",
    "\n",
    "api = SpotifyCharts()\n",
    "connector = sqlalchemy.create_engine(\"sqlite:///spotifycharts_2020.db\", echo=False)\n",
    "api.top200Daily(output_file = \"top_200_daily_2020.csv\", output_db = connector, webhook = \"https://mywebhookssite.com/post/\", \n",
    "                start = fecha_inicial_2020, end = fecha_fin_2020, region = [\"es\"])\n",
    "\n",
    "\n",
    "# Descarga año 2019\n",
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "import sqlalchemy\n",
    "\n",
    "api = SpotifyCharts()\n",
    "connector = sqlalchemy.create_engine(\"sqlite:///spotifycharts_2019.db\", echo=False)\n",
    "api.top200Daily(output_file = \"top_200_daily_2019.csv\", output_db = connector, webhook = \"https://mywebhookssite.com/post/\", \n",
    "                start = fecha_inicial_2019, end = fecha_fin_2019, region = [\"es\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position      0\n",
      "Track Name    0\n",
      "Artist        0\n",
      "Streams       0\n",
      "date          0\n",
      "region        0\n",
      "spotify_id    0\n",
      "dtype: int64\n",
      "2020: (12200, 7)\n",
      "2019: (12200, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tusa</td>\n",
       "      <td>KAROL G</td>\n",
       "      <td>446086</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>es</td>\n",
       "      <td>7k4t7uLgtOxPwTpFmtJNTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>399788</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>es</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tattoo</td>\n",
       "      <td>Rauw Alejandro</td>\n",
       "      <td>380503</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>es</td>\n",
       "      <td>7na7Bk98usp84FaOJFPv3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Diosa</td>\n",
       "      <td>Myke Towers</td>\n",
       "      <td>336910</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>es</td>\n",
       "      <td>3JHpk0DOTOzyh0777JFAky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rojo</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>327388</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>es</td>\n",
       "      <td>4uziEsK1yiqdauKVDPsmVG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position  Track Name          Artist  Streams        date region  \\\n",
       "0         1        Tusa         KAROL G   446086  2020-03-14     es   \n",
       "1         2  La Difícil       Bad Bunny   399788  2020-03-14     es   \n",
       "2         3      Tattoo  Rauw Alejandro   380503  2020-03-14     es   \n",
       "3         4       Diosa     Myke Towers   336910  2020-03-14     es   \n",
       "4         5        Rojo        J Balvin   327388  2020-03-14     es   \n",
       "\n",
       "               spotify_id  \n",
       "0  7k4t7uLgtOxPwTpFmtJNTY  \n",
       "1  6NfrH0ANGmgBXyxgV2PeXt  \n",
       "2  7na7Bk98usp84FaOJFPv3d  \n",
       "3  3JHpk0DOTOzyh0777JFAky  \n",
       "4  4uziEsK1yiqdauKVDPsmVG  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos la tabla con los datos y miramos a ver qué tal están\n",
    "data_top200_2020= pd.read_csv(\"top_200_daily_2020.csv\")\n",
    "data_top200_2019= pd.read_csv(\"top_200_daily_2019.csv\")\n",
    "print(data_top200_2020.isnull().sum())\n",
    "print('2020:', data_top200_2020.shape)\n",
    "print('2019:',data_top200_2019.shape)\n",
    "data_top200_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position               int64\n",
      "Track Name            object\n",
      "Artist                object\n",
      "Streams                int64\n",
      "date          datetime64[ns]\n",
      "spotify_id            object\n",
      "year                   int64\n",
      "dtype: object\n",
      "Position        200\n",
      "Track Name      738\n",
      "Artist          297\n",
      "Streams       20942\n",
      "date            122\n",
      "spotify_id      807\n",
      "year              2\n",
      "dtype: int64\n",
      "(24400, 7)\n"
     ]
    }
   ],
   "source": [
    "# Importamos con las columnas que nos interesan\n",
    "data_top200_2020 = pd.read_csv(\"top_200_daily_2020.csv\", parse_dates= [\"date\"], usecols=['Position','Track Name', 'Artist', 'date', 'Streams', 'date', 'spotify_id'])\n",
    "data_top200_2019 = pd.read_csv(\"top_200_daily_2019.csv\", parse_dates= [\"date\"], usecols=['Position','Track Name', 'Artist', 'date', 'Streams', 'date', 'spotify_id'])\n",
    "#Meto el año en nueva columnas columnas\n",
    "data_top200_2020['year'] = pd.DatetimeIndex(data_top200_2020['date']).year\n",
    "data_top200_2019['year'] = pd.DatetimeIndex(data_top200_2019['date']).year\n",
    "\n",
    "#Concateno los datos de los dos años\n",
    "data_top200 = pd.concat([data_top200_2020, data_top200_2019], axis=0,)\n",
    "\n",
    "print(data_top200.dtypes)\n",
    "print(data_top200.nunique()) # Ojo, debería haber el mismo número de Track Names y spotify ID!!\n",
    "print(data_top200.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>date</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>399788</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>372705</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>389384</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>390067</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>2</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>392738</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>18</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>165292</td>\n",
       "      <td>2020-05-09</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11426</th>\n",
       "      <td>27</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>151313</td>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11628</th>\n",
       "      <td>29</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>166240</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11828</th>\n",
       "      <td>29</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>143671</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12029</th>\n",
       "      <td>30</td>\n",
       "      <td>La Difícil</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>144698</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>6NfrH0ANGmgBXyxgV2PeXt</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Position  Track Name     Artist  Streams       date  \\\n",
       "1             2  La Difícil  Bad Bunny   399788 2020-03-14   \n",
       "201           2  La Difícil  Bad Bunny   372705 2020-03-15   \n",
       "401           2  La Difícil  Bad Bunny   389384 2020-03-16   \n",
       "601           2  La Difícil  Bad Bunny   390067 2020-03-17   \n",
       "801           2  La Difícil  Bad Bunny   392738 2020-03-18   \n",
       "...         ...         ...        ...      ...        ...   \n",
       "11217        18  La Difícil  Bad Bunny   165292 2020-05-09   \n",
       "11426        27  La Difícil  Bad Bunny   151313 2020-05-10   \n",
       "11628        29  La Difícil  Bad Bunny   166240 2020-05-11   \n",
       "11828        29  La Difícil  Bad Bunny   143671 2020-05-12   \n",
       "12029        30  La Difícil  Bad Bunny   144698 2020-05-13   \n",
       "\n",
       "                   spotify_id  year  \n",
       "1      6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "201    6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "401    6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "601    6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "801    6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "...                       ...   ...  \n",
       "11217  6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "11426  6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "11628  6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "11828  6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "12029  6NfrH0ANGmgBXyxgV2PeXt  2020  \n",
       "\n",
       "[61 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_top200.loc[data_top200['spotify_id'] == '6NfrH0ANGmgBXyxgV2PeXt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>Streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00ZBADBKZGwnzGIAA6U9Fb</td>\n",
       "      <td>44107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>017PF4Q3l4DBUiWoXk4OWT</td>\n",
       "      <td>2814658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>047WmwIeerHyIUstFAEz5A</td>\n",
       "      <td>3060737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04wvWMRKKxK9TGG4IPk32d</td>\n",
       "      <td>90156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>059bcIhyc2SBwm6sw2AZzd</td>\n",
       "      <td>6447442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               spotify_id  Streams\n",
       "0  00ZBADBKZGwnzGIAA6U9Fb    44107\n",
       "1  017PF4Q3l4DBUiWoXk4OWT  2814658\n",
       "2  047WmwIeerHyIUstFAEz5A  3060737\n",
       "3  04wvWMRKKxK9TGG4IPk32d    90156\n",
       "4  059bcIhyc2SBwm6sw2AZzd  6447442"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupar sumas y convertir en Dataframe\n",
    "data_top200_sumastreams = data_top200.groupby('spotify_id')['Streams'].sum()\n",
    "data_top200_sumastreams = pd.DataFrame({'spotify_id':data_top200_sumastreams.index, 'Streams':data_top200_sumastreams.values})\n",
    "print(data_top200_sumastreams.shape)\n",
    "data_top200_sumastreams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo 24400 filas en canciones, de las cuales hay 738 canciones únicas (Dataframe 1, si hago un groupby para que me sume los Streams de las mismas canciones se hace sin problema y tengo un Dataframe 2\n",
    "\n",
    "Pero ahora no quiero perder las demás columnas haciendo groupby, pero es la forma fácil de hacer las sumas de Streams. Pero entonces quisiera añadir en nueva columna en el dataframe 1 el dato de Streams totales de dicha canción. Lo ideal sería hacer un bucle que mirara si el Track name es el mismo, entonces en una nueva columna añadiría ese dato para esa fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-2269432d3f19>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-2269432d3f19>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    XX =data_top200['spotify_id'].map(lambda x: data_top200_sumastreams['Streams'] if data_top200['Track Name'] == data_top200_sumastreams['Track Name'])\u001b[0m\n\u001b[0m                                                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# OOOOOtra prueba\n",
    "\n",
    "data_top200['spotify_id'].map(lambda x: data_top200_sumastreams['Streams'] if data_top200['Track Name'] == data_top200_sumastreams['Track Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      00ZBADBKZGwnzGIAA6U9Fb\n",
       "1      017PF4Q3l4DBUiWoXk4OWT\n",
       "2      047WmwIeerHyIUstFAEz5A\n",
       "3      04wvWMRKKxK9TGG4IPk32d\n",
       "4      059bcIhyc2SBwm6sw2AZzd\n",
       "                ...          \n",
       "802    7wCqmkAjudO0oKRASmv8Wg\n",
       "803    7xX3wvvcZvxGCa06KlgTCp\n",
       "804    7ytR5pFWmSjzHJIeQkgog4\n",
       "805    7z9chavxReUpyOZoAkUnUb\n",
       "806    7zAGi1cps7yYhAajGXlFTH\n",
       "Name: spotify_id, Length: 807, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_top200_sumastreams['spotify_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-306208444fa4>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-306208444fa4>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if (data_top200['spotify_id'] == data_top200_sumastreams['spotify_id']:\u001b[0m\n\u001b[0m                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def conditions(s):\n",
    "    for songcode in data_top200['spotify_id']:\n",
    "        if (data_top200['spotify_id'] == data_top200_sumastreams['spotify_id']:\n",
    "            return data_top200_sumastreams['Streams']\n",
    "\n",
    "data_top200['NewColumn'] = data_top200.apply(conditions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    if data_top200['spotify_id'] == data_top200_sumastreams['spotify_id']:\n",
    "        data_top200_sumastreams['spotify_id'] =\n",
    "    elif row['A'] > row['B']:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (24400,) (738,2) (24400,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-06ee86712c68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m data_top200['Streams'] = np.where((data_top200['Track Name']  == data_top200_sumastreams['Track Name']), #Identifies the case to apply to\n\u001b[1;32m      2\u001b[0m                            \u001b[0mdata_top200_sumastreams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Streams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m#This is the value that is inserted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                            data_top200['Streams'])      #This is the column that is affected\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (24400,) (738,2) (24400,) "
     ]
    }
   ],
   "source": [
    "#Otra posible forma\n",
    "\n",
    "data_top200['Streams'] = np.where((data_top200['Track Name']  == data_top200_sumastreams['Track Name']), #Identifies the case to apply to\n",
    "                           data_top200_sumastreams['Streams'],      #This is the value that is inserted\n",
    "                           data_top200['Streams'])      #This is the column that is affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_top200.Tr[data_top200.Streams == data_top200_sumastreams['Streams'] = df.col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUEVOOOO\n",
    "# https://datascience.stackexchange.com/questions/56668/pandas-change-value-of-a-column-based-another-column-condition\n",
    "\n",
    "\n",
    "data['column2'] = np.where((data['column1'] > 90)\n",
    "                           & (data['column2'] ==2), #For rows with column1 > 90\n",
    "                           data['column3'],      #We place column3 values\n",
    "                           data['column2'])      #In column two\n",
    "\n",
    "\n",
    "\n",
    "data['column2'] = np.where((data['column1'] < 30)\n",
    "                           & (data['column2'] ==2), #Identifies the case to apply to\n",
    "                           data['column2'],      #This is the value that is inserted\n",
    "                           data['column2'])      #This is the column that is affected\n",
    "data['column2'] = np.where((data['column1'] > 90)\n",
    "                           & (data['column2'] ==2), #For rows with column1 > 90\n",
    "                           data['column3'],      #We place column3 values\n",
    "                           data['column2'])      #In column two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora habría que: en las canciones que coincidan en el nombre sustituir por dataframe del día por streams totales.\n",
    "data_top200_sumastreams = data_top200.groupby('Track Name')\n",
    "data_top200_sumastreams.head()\n",
    "\n",
    "data_top200['Streams'] = df['Streams'].map(lambda x: data_top200_sumastreams['Streams']\n",
    "                                           if data_top200['Track Name'] == data_top200_sumastreams['Track Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prueba para crear lista con canciones únicas\n",
    "songs_list = []\n",
    "\n",
    "for song in data_top200['spotify_id']:\n",
    "    if song not in songs_list:\n",
    "        songs_list.append(song)\n",
    "        \n",
    "\n",
    "len(songs_list)\n",
    "#Que se sumen los streams y se quiten columnas\n",
    "\n",
    "songscode_list = []\n",
    "\n",
    "for songcode in data_top200['spotify_id']:\n",
    "    if songcode not in songscode_list:\n",
    "        songscode_list.append(songcode)\n",
    "    else: #Está en lista y quiero ahora sumar los strings de ese songcode\n",
    "        for songcode in data_top200['spotify_id']:\n",
    "            data_top200['Streams'].sum()\n",
    "\n",
    "        \n",
    "#map(lambda x: lasumaaaaa if songcode == data_top200['spotify_id'], songs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
